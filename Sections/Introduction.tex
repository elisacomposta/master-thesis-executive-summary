\section{Introduction}
\label{sec:introduction}

Online social networks are a central aspect of the daily life of millions of people. They are not just communication platforms but digital spaces where users express their emotions and shape opinions.
For this reason, they offer a valuable opportunity for studying social dynamics.
This is the main focus of Computational Social Science, interdisciplinary field that uses computational methods to study and explain human behavior and social interactions.

To study these social processes in controlled conditions, simulators are used to recreate virtual environments.
Among these, Agent-Based Modeling (ABM) simulates social systems by defining individual agents that follow simple rules, and whose interactions lead to collective behaviors.
However, traditional ABMs struggle to capture the full complexity of human behavior, such as language tone and emotions.

Large Language Models (LLMs) offer an improvement by enabling agents that simulate conversations in natural language, and express opinions and emotions.

A particularly important aspect of online social media is the spread of misinformation and disinformation, which can influence opinions and social dynamics. 
Simulating these phenomena can help us better understand their impact and explore possible mitigation strategies.

This work explores the behavior of LLM-based agents in a simulated social network. 
Agents are initialized with realistic profiles, calibrated on real-world data collected around the 2022 Italian political elections. An existing social media simulator has been extended to include mechanisms for opinion modeling and the generation of misinformation. 
The aim is to analyze how LLM agents simulate online conversations, interact, and evolve their opinions under different scenarios, offering insights into strengths and current limitations of using them to model social dynamics.

